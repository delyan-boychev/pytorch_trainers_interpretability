{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretability plots SmallImagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_trainers_interpretability.interpretability_eval import IntegratedGrad, ShapEval, RepVisualization\n",
    "from pytorch_trainers_interpretability.tools import show_image_column, show_image_row\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from textwrap import wrap\n",
    "from pytorch_trainers_interpretability.interpretability_eval.integrated_grad import IntegratedGrad\n",
    "from pytorch_trainers_interpretability.attack import Attacker, L2Step, LinfStep\n",
    "from pytorch_trainers_interpretability.models.resnet  import ResNet50\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import json\n",
    "import torchvision\n",
    "import copy\n",
    "import os\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1619V_hLgH3mhZSVCYuYO1G7y0088A1vq' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1619V_hLgH3mhZSVCYuYO1G7y0088A1vq\" -O \"smallimagenet.tar.gz\" && rm -rf /tmp/cookies.txt\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1zpHIJ_dPYb6-Seqtbk9YoWSItvdwU-GO' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1zpHIJ_dPYb6-Seqtbk9YoWSItvdwU-GO\" -O \"standard_smimagenet.pt\" && rm -rf /tmp/cookies.txt\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1_5bKIy4n0rtbRy0YK64BUblnBqUnISMv' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1_5bKIy4n0rtbRy0YK64BUblnBqUnISMv\" -O \"robust_l2_smimagenet.pt\" && rm -rf /tmp/cookies.txt\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://drive.google.com/uc?export=download&id=12O5HxjqcSzjt9-mGfapYeZ-nOfsMopIM' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=12O5HxjqcSzjt9-mGfapYeZ-nOfsMopIM\" -O \"robust_linf_smimagenet.pt\" && rm -rf /tmp/cookies.txt\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1t71KG_u-X-LCAFJ94Kg0pqNBajumEEsu' -O \"smallimagenet150_labels.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_grads_compare_3(standard, robust_l2, robust_linf, images, labels, classes, normalizer=lambda x: x):\n",
    "    integrated_grad = IntegratedGrad(standard, normalizer=normalizer)\n",
    "    integrated_grad2 = IntegratedGrad(robust_l2, normalizer=normalizer)\n",
    "    integrated_grad3 = IntegratedGrad(robust_linf, normalizer=normalizer)\n",
    "    num_img = labels.shape[0]\n",
    "    labels_text = [ '\\n'.join(wrap(classes[l.item()], 20)) for l in labels.cpu() ]\n",
    "    num_cols = np.ceil(num_img/8).astype(int)\n",
    "    fig = plt.figure(figsize=(26*num_cols, 80))\n",
    "    subfigs = fig.subfigures(nrows=1, ncols=num_cols)\n",
    "    k = 0\n",
    "    for j, sub in enumerate(subfigs):\n",
    "        sub2 = sub.subfigures(nrows=8, ncols=1)\n",
    "        for i, subfig in enumerate(sub2):\n",
    "            if num_img == k:\n",
    "                break\n",
    "            axs = subfig.subplots(nrows=1, ncols=4)\n",
    "            if i is 0:\n",
    "                axs[0].set_title(\"Original image\", fontsize=40)\n",
    "                axs[1].set_title(\"Standard model\", fontsize=40)\n",
    "                axs[2].set_title(r\"Robust $l_{2}$\", fontsize=40)\n",
    "                axs[3].set_title(r\"Robust $l_{\\infty}$\", fontseize=40)\n",
    "            img = images[k:k+1].cuda()\n",
    "            img = normalizer(img)\n",
    "            pr = standard(img)\n",
    "            pr2 = robust_l2(img)\n",
    "            pr3 = robust_linf(img)\n",
    "            image = images[k].cpu().permute(1, 2, 0).numpy()\n",
    "            grad = integrated_grad.random_baseline_integrated_grads(image, pr.argmax(dim=1).item(), steps=100, num_random_trials=10, batch_size=100)\n",
    "            grad2 = integrated_grad2.random_baseline_integrated_grads(image, pr2.argmax(dim=1).item(), steps=100, num_random_trials=10, batch_size=100)\n",
    "            grad3 = integrated_grad3.random_baseline_integrated_grads(image, pr3.argmax(dim=1).item(), steps=100, num_random_trials=10, batch_size=100)\n",
    "            pred = '\\n'.join(wrap(classes[pr.argmax(dim=1).item()], 10))\n",
    "            pred2 = '\\n'.join(wrap(classes[pr2.argmax(dim=1).item()], 10))\n",
    "            pred3 = '\\n'.join(wrap(classes[pr3.argmax(dim=1).item()], 10))\n",
    "            axs[0].set_xlabel('\\n'.join(wrap(labels_text[k], 10)), fontsize=35)\n",
    "            axs[0].imshow(image)\n",
    "            axs[1].set_xlabel(f\"Class: {pred}\\n Prob: {torch.softmax(pr, dim=1).amax(dim=1).item():.2f}\", fontsize=35)\n",
    "            axs[1].imshow(integrated_grad.visualization(grad, image))\n",
    "            axs[2].set_xlabel(f\"Class: {pred2}\\n Prob: {torch.softmax(pr2, dim=1).amax(dim=1).item():.2f}\", fontsize=35)\n",
    "            axs[2].imshow(integrated_grad2.visualization(grad2, image))\n",
    "            axs[3].set_xlabel(f\"Class: {pred3}\\n Prob: {torch.softmax(pr3, dim=1).amax(dim=1).item():.2f}\", fontsize=35)\n",
    "            axs[3].imshow(integrated_grad3.visualization(grad3, image))\n",
    "            for t in range(4):\n",
    "                axs[t].set_xticklabels([])\n",
    "                axs[t].set_yticklabels([])\n",
    "            k+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valdir = os.path.join(\"./smallimagenet\", 'test')\n",
    "normalize = transforms.Normalize(mean=[0.4808, 0.4512, 0.4072],\n",
    "                                     std=[0.2687, 0.2610, 0.2742])\n",
    "transform_test = transforms.Compose([\n",
    "          transforms.Resize(140),\n",
    "          transforms.CenterCrop(128),\n",
    "          transforms.ToTensor(),\n",
    "    ])\n",
    "testset = datasets.ImageFolder(valdir, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=200,\n",
    "                                         shuffle=True)\n",
    "f = open('./smallimagenet150_labels.json')\n",
    "classes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(num_classes=150)\n",
    "model2 = ResNet50(num_classes=150)\n",
    "model3 = ResNet50(num_classes=150)\n",
    "model.load_state_dict(torch.load(\"./standard_smimagenet.pt\")[\"model_state_dict\"])\n",
    "model2.load_state_dict(torch.load(\"./robust_l2_smimagenet.pt\")[\"model_state_dict\"])\n",
    "model3.load_state_dict(torch.load(\"./robust_linf_smimagenet.pt\")[\"model_state_dict\"])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model2.to(device)\n",
    "model3.to(device)\n",
    "model.eval()\n",
    "model2.eval()\n",
    "model3.eval()\n",
    "vis = RepVisualization(model, normalizer=normalize)\n",
    "vis2 = RepVisualization(model2, normalizer=normalize)\n",
    "vis3 = RepVisualization(model3, normalizer=normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels =  next(iter(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representation Inversion\n",
    "im = torch.concat([images[3:4] for i in range(5)])\n",
    "r = torch.rand_like(images[0:2])/20 + 0.5\n",
    "im_n = torch.concat([images[0:3], r], 0)\n",
    "res = [im.cpu()]\n",
    "res.append(vis2.rep_inversion(im, im_n.clone()).cpu())\n",
    "res.append(vis3.rep_inversion(im, im_n.clone()).cpu())\n",
    "res.append(vis.rep_inversion(im, im_n.clone()).cpu())\n",
    "show_image_row(res, [\"Original image\", \"Source\", r\"Robust $l_{2}$\", r\"Robust $l_{\\lnfty}$\", \"Standard\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels =  next(iter(testloader))\n",
    "cl = np.random.choice(150, (5, 1), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class Specific Image Generation\n",
    "r = torch.rand_like(images[0:2])/20 + 0.5\n",
    "im_n = torch.concat([images[0:3], r], 0)\n",
    "res = [im_n.cpu()]\n",
    "res2 = [im_n.cpu()]\n",
    "res3 = [im_n.cpu()]\n",
    "for i in len(cl):\n",
    "    res.append(vis2.class_im_gen(im_n.clone(), cl[i]).cpu())\n",
    "    res2.append(vis3.class_im_gen(im_n.clone(), cl[i]).cpu())\n",
    "    res3.append(vis.class_im_gen(im_n.clone(), cl[i]).cpu())\n",
    "list_labels = [\"Soruce\"] + [ classes[cl[i]] for i in len(cl)]\n",
    "show_image_column(list_labels, res)\n",
    "show_image_column(list_labels, res2)\n",
    "show_image_column(list_labels, res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAP and Integrated Gradients\n",
    "torch.cuda.empty_cache()\n",
    "shapeval = ShapEval(model, classes, normalize)\n",
    "shapeval.gradient_exp(images[:176], images[176:200], labels[176:200])\n",
    "shapeval2 = ShapEval(model2, classes, normalize)\n",
    "shapeval2.gradient_exp(images[:176], images[176:200], labels[176:200])\n",
    "int_grads_compare_3(model, model2, model3, images[176:200], labels[176:200], classes, normalize)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec 19 2022, 17:35:49) [GCC 12.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
