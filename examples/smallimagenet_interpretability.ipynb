{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretability plots SmallImagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_trainers_interpretability.interpretability_eval import IntegratedGrad\n",
    "from pytorch_trainers_interpretability.interpretability_eval.lime import LimeEval\n",
    "from pytorch_trainers_interpretability.interpretability_eval import ShapEval\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from textwrap import wrap\n",
    "from pytorch_trainers_interpretability.trainers import BasicTrainer, AdversarialTrainer\n",
    "from pytorch_trainers_interpretability.interpretability_eval.integrated_grad import IntegratedGrad\n",
    "from pytorch_trainers_interpretability.attack import Attacker, L2Step, LinfStep\n",
    "from pytorch_trainers_interpretability.models.resnet  import ResNet50\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import json\n",
    "import torchvision\n",
    "import copy\n",
    "import os\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1619V_hLgH3mhZSVCYuYO1G7y0088A1vq' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1619V_hLgH3mhZSVCYuYO1G7y0088A1vq\" -O \"smallimagenet.tar.gz\" && rm -rf /tmp/cookies.txt\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1zpHIJ_dPYb6-Seqtbk9YoWSItvdwU-GO' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1zpHIJ_dPYb6-Seqtbk9YoWSItvdwU-GO\" -O \"regular_smimagenet.pt\" && rm -rf /tmp/cookies.txt\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1_5bKIy4n0rtbRy0YK64BUblnBqUnISMv' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1_5bKIy4n0rtbRy0YK64BUblnBqUnISMv\" -O \"robust_smimagenet.pt\" && rm -rf /tmp/cookies.txt\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1t71KG_u-X-LCAFJ94Kg0pqNBajumEEsu' -O \"smallimagenet150_labels.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_grads_compare_regular_robust(regular, robust, images, labels, classes, normalizer=lambda x: x):\n",
    "    integrated_grad = IntegratedGrad(regular, normalizer=normalizer)\n",
    "    integrated_grad2 = IntegratedGrad(robust, normalizer=normalizer)\n",
    "    num_img = labels.shape[0]\n",
    "    labels_text = [ '\\n'.join(wrap(classes[l.item()], 20)) for l in labels.cpu() ]\n",
    "    num_cols = np.ceil(num_img/9).astype(int)\n",
    "    fig = plt.figure(figsize=(20*num_cols, 85))\n",
    "    subfigs = fig.subfigures(nrows=1, ncols=num_cols)\n",
    "    k = 0\n",
    "    for j, sub in enumerate(subfigs):\n",
    "        sub2 = sub.subfigures(nrows=9, ncols=1)\n",
    "        for i, subfig in enumerate(sub2):\n",
    "            if num_img == k:\n",
    "                break\n",
    "            axs = subfig.subplots(nrows=1, ncols=3)\n",
    "            if i is 0:\n",
    "                axs[0].set_title(\"Original image\", fontsize=40)\n",
    "                axs[1].set_title(\"Regular model\", fontsize=40)\n",
    "                axs[2].set_title(\"Robust model\", fontsize=40)\n",
    "            img = images[k:k+1].cuda()\n",
    "            img = normalizer(img)\n",
    "            pr = regular(img)\n",
    "            pr2 = robust(img)\n",
    "            image = images[k].cpu().permute(1, 2, 0).numpy()\n",
    "            grad = integrated_grad.random_baseline_integrated_grads(image, pr.argmax(dim=1), steps=100, num_random_trials=10, batch_size=100)\n",
    "            grad2 = integrated_grad2.random_baseline_integrated_grads(image, pr2.argmax(dim=1), steps=100, num_random_trials=10, batch_size=100)\n",
    "            pred = '\\n'.join(wrap(classes[pr.argmax(dim=1).item()], 10))\n",
    "            pred2 = '\\n'.join(wrap(classes[pr2.argmax(dim=1).item()], 10))\n",
    "            axs[0].set_xlabel('\\n'.join(wrap(labels_text[k], 10)), fontsize=35)\n",
    "            axs[0].imshow(image)\n",
    "            axs[1].set_xlabel(f\"Class: {pred}\\n Prob: {torch.softmax(pr, dim=1).amax(dim=1).item():.2f}\", fontsize=35)\n",
    "            axs[1].imshow(integrated_grad.visualization(grad, image))\n",
    "            axs[2].set_xlabel(f\"Class: {pred2}\\n Prob: {torch.softmax(pr2, dim=1).amax(dim=1).item():.2f}\", fontsize=35)\n",
    "            axs[2].imshow(integrated_grad2.visualization(grad2, image))\n",
    "            axs[0].set_xticklabels([])\n",
    "            axs[0].set_yticklabels([])\n",
    "            axs[1].set_xticklabels([])\n",
    "            axs[1].set_yticklabels([])\n",
    "            axs[2].set_xticklabels([])\n",
    "            axs[2].set_yticklabels([])\n",
    "            k+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lime_compare_regular_robust(regular, robust, images, labels, classes, normalizer=lambda x: x):\n",
    "    leval = LimeEval(regular, normalizer=normalizer)\n",
    "    leval2 = LimeEval(robust, normalizer=normalizer)\n",
    "    num_img = labels.shape[0]\n",
    "    labels_text = [ '\\n'.join(wrap(classes[l.item()], 20)) for l in labels.cpu() ]\n",
    "    num_cols = np.ceil(num_img/9).astype(int)\n",
    "    fig = plt.figure(figsize=(20*num_cols, 80))\n",
    "    subfigs = fig.subfigures(nrows=1, ncols=num_cols)\n",
    "    k = 0\n",
    "    for j, sub in enumerate(subfigs):\n",
    "        sub2 = sub.subfigures(nrows=9, ncols=1)\n",
    "        for i, subfig in enumerate(sub2):\n",
    "            if num_img == k:\n",
    "                break\n",
    "            axs = subfig.subplots(nrows=1, ncols=3)\n",
    "            if i is 0:\n",
    "                axs[0].set_title(\"Original image\", fontsize=40)\n",
    "                axs[1].set_title(\"Regular model\", fontsize=40)\n",
    "                axs[2].set_title(\"Robust model\", fontsize=40)\n",
    "            img = images[k:k+1].cuda()\n",
    "            img = normalizer(img)\n",
    "            pr = regular(img)\n",
    "            pr2 = robust(img)\n",
    "            image = images[k].cpu().permute(1, 2, 0).numpy()\n",
    "            plot1 = leval.explain_model(image)\n",
    "            plot2 = leval2.explain_model(image)\n",
    "            pred = '\\n'.join(wrap(classes[pr.argmax(dim=1).item()], 10))\n",
    "            pred2 = '\\n'.join(wrap(classes[pr2.argmax(dim=1).item()], 10))\n",
    "            axs[0].set_xlabel('\\n'.join(wrap(labels_text[k], 10)), fontsize=35)\n",
    "            axs[0].imshow(image)\n",
    "            axs[1].set_xlabel(f\"Class: {pred}\\n Prob: {torch.softmax(pr, dim=1).amax(dim=1).item():.2f}\", fontsize=35)\n",
    "            axs[1].imshow(plot1)\n",
    "            axs[2].set_xlabel(f\"Class: {pred2}\\n Prob: {torch.softmax(pr2, dim=1).amax(dim=1).item():.2f}\", fontsize=35)\n",
    "            axs[2].imshow(plot2)\n",
    "            axs[0].set_xticklabels([])\n",
    "            axs[0].set_yticklabels([])\n",
    "            axs[1].set_xticklabels([])\n",
    "            axs[1].set_yticklabels([])\n",
    "            axs[2].set_xticklabels([])\n",
    "            axs[2].set_yticklabels([])\n",
    "            k+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindir = os.path.join(\"/home/server/smallimagenet\", 'train')\n",
    "valdir = os.path.join(\"/home/server/smallimagenet\", 'test')\n",
    "normalize = transforms.Normalize(mean=[0.4808, 0.4512, 0.4072],\n",
    "                                     std=[0.2687, 0.2610, 0.2742])\n",
    "transform_train =   transforms.Compose([\n",
    "          transforms.Resize(140),\n",
    "          transforms.RandomResizedCrop(128),\n",
    "          transforms.RandomHorizontalFlip(),\n",
    "          transforms.ToTensor(),\n",
    "    ])\n",
    "transform_test = transforms.Compose([\n",
    "          transforms.Resize(140),\n",
    "          transforms.CenterCrop(128),\n",
    "          transforms.ToTensor(),\n",
    "    ])\n",
    "trainset = datasets.ImageFolder(traindir, transform=transform_train)\n",
    "testset = datasets.ImageFolder(valdir, transform=transform_test)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=200,\n",
    "                                         shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=200,\n",
    "                                         shuffle=True)\n",
    "f = open('./smallimagenet150_labels.json')\n",
    "classes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(num_classes=150)\n",
    "model2 = ResNet50(num_classes=150)\n",
    "model.load_state_dict(torch.load(\"./regular_smimagenet.pt\")[\"model_state_dict\"])\n",
    "model2.load_state_dict(torch.load(\"./robust_smimagenet.pt\")[\"model_state_dict\"])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model2.to(device)\n",
    "model.eval()\n",
    "model2.eval()\n",
    "integrated_grad = IntegratedGrad(model, normalizer=normalize)\n",
    "integrated_grad2 = IntegratedGrad(model2, normalizer=normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels =  next(iter(testloader))\n",
    "images_b, _ = next(iter(trainloader))\n",
    "shapeval = ShapEval(model, classes, normalize)\n",
    "shapeval.nat_deep_exp(images_b[:100], images[:36], labels[:36])\n",
    "plt.savefig(\"./smallimagenet_shap1.pdf\")\n",
    "shapeval2 = ShapEval(model2, classes, normalize)\n",
    "shapeval2.nat_deep_exp(images_b[:100], images[:36], labels[:36])\n",
    "plt.savefig(\"./smallimagenet_shap2.pdf\")\n",
    "int_grads_compare_regular_robust(model, model2, images[:36], labels[:36], classes, normalize)\n",
    "plt.savefig(\"./smallimagenet_int_grads.pdf\")\n",
    "lime_compare_regular_robust(model, model2, images[:36], labels[:36], classes, normalize)\n",
    "plt.savefig(\"./smallimagenet_lime_plots.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
