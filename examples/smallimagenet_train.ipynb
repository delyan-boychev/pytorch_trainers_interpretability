{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretability analysis CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation of needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "!pip install build\n",
    "try:\n",
    "    import pytorch_trainers_interpretability\n",
    "except:\n",
    "    !cd .. && python -m build\n",
    "    clear_output()\n",
    "    !pip install --force --upgrade ../dist/pytorch_trainers_interpretability-0.0.1-py3-none-any.whl\n",
    "    !pip install torchmetrics[image] tqdm\n",
    "clear_output()\n",
    "try:\n",
    "    import pytorch_trainers_interpretability\n",
    "except:\n",
    "    raise Exception(\"Packages not installed! Please try again!\")\n",
    "print(\"Installation completed!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard and Adversarial training Small ImageNet 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_trainers_interpretability.trainers import StandardTrainer, AdversarialTrainer\n",
    "from pytorch_trainers_interpretability.attack import L2Step\n",
    "from pytorch_trainers_interpretability.models.resnet  import ResNet50\n",
    "from torchvision import datasets, transforms\n",
    "import json\n",
    "import os\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"./smallimagenet\"):\n",
    "    !python gdownload.py \"1_nc-VVObGiOoS73gEH-UhVUsIytU0YRK\" \"smallimagenet.tar.gz\"\n",
    "    file = tarfile.open('smallimagenet.tar.gz')\n",
    "    file.extractall('./')\n",
    "    file.close()\n",
    "    os.remove('./smallimagenet.tar.gz')\n",
    "if not os.path.isfile(\"./Small ImageNet 150_labels.json\"):\n",
    "    !python gdownload.py \"1t71KG_u-X-LCAFJ94Kg0pqNBajumEEsu\" \"Small ImageNet 150_labels.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindir = os.path.join(\"./smallimagenet\", 'train')\n",
    "valdir = os.path.join(\"./smallimagenet\", 'test')\n",
    "normalize = transforms.Normalize(mean=[0.4808, 0.4512, 0.4072],\n",
    "                                     std=[0.2687, 0.2610, 0.2742])\n",
    "trainset = datasets.ImageFolder(traindir)\n",
    "transform_train =   transforms.Compose([\n",
    "          transforms.Resize(140),\n",
    "          transforms.RandomResizedCrop(128),\n",
    "          transforms.RandomHorizontalFlip(),\n",
    "          transforms.ToTensor(),\n",
    "    ])\n",
    "transform_test = transforms.Compose([\n",
    "          transforms.Resize(140),\n",
    "          transforms.CenterCrop(128),\n",
    "          transforms.ToTensor(),\n",
    "    ])\n",
    "testset = datasets.ImageFolder(valdir, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=200,\n",
    "                                         shuffle=True)  \n",
    "f = open('./Small ImageNet 150_labels.json')\n",
    "\n",
    "classes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(num_classes=150)\n",
    "training_kwargs = {\n",
    "    \"model\": model,\n",
    "    \"pretrained\": False,\n",
    "    \"batch_size\": 200,\n",
    "    \"adv_step\": L2Step,\n",
    "    \"adv_epsilon\": 0.5,\n",
    "    \"adv_iter\": 20,\n",
    "    \"adv_lr\": 0.1,\n",
    "    \"lr\": 0.0001,\n",
    "    \"epochs\": 100,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"weight_decay\": 5e-4,\n",
    "    \"lr_scheduler\": \"CosineAnnealingLR\",\n",
    "    \"testset\": testset,\n",
    "    \"trainset\": trainset,\n",
    "    \"transforms_train\": transform_train,\n",
    "    \"transforms_test\": transform_test,\n",
    "    \"input_normalizer\": normalize,\n",
    "    \"save_path\": \"./smimagenet_standard_model\"\n",
    "}\n",
    "trainer = StandardTrainer(**training_kwargs)\n",
    "trainer()\n",
    "trainer.eval()\n",
    "trainer.eval_adv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = ResNet50(num_classes=150)\n",
    "training_kwargs2 = {\n",
    "    \"model\": model2,\n",
    "    \"pretrained\": False,\n",
    "    \"batch_size\": 200,\n",
    "    \"adv_step\": L2Step,\n",
    "    \"adv_epsilon\": 0.5,\n",
    "    \"adv_iter\": 20,\n",
    "    \"adv_lr\": 0.1,\n",
    "    \"lr\": 0.0001,\n",
    "    \"epochs\": 100,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"weight_decay\": 5e-4,\n",
    "    \"lr_scheduler\": \"CosineAnnealingLR\",\n",
    "    \"testset\": testset,\n",
    "    \"trainset\": trainset,\n",
    "    \"transforms_train\": transform_train,\n",
    "    \"transforms_test\": transform_test,\n",
    "    \"input_normalizer\": normalize,\n",
    "    \"save_path\": \"./smimagenet_robust_l2_model\"\n",
    "}\n",
    "trainer2 = AdversarialTrainer(**training_kwargs2)\n",
    "trainer2()\n",
    "trainer2.eval_nat()\n",
    "trainer2.eval_adv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
