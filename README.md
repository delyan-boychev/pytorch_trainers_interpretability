# Pytorch Trainers and Interpretability Evaluators

_(Increasing Computer Vision Models Interpretability)_

Contact: delyan.boychev05@gmail.com 

With the perpetual increase of complexity of the state-of-the-art deep neural networks, it becomes more and more challenging to maintain their transparency. The scope of this work is to evaluate the effects of various techniques that have been shown to make computer vision models more explainable, such as adversarial training: to study their impacts on local and global interpretability and to compare their respective performances.

## SmallImageNet150

SmallImageNet150 dataset can be found [here](https://drive.google.com/file/d/1619V_hLgH3mhZSVCYuYO1G7y0088A1vq/view?usp=sharing) and its labels [here](https://drive.google.com/file/d/1t71KG_u-X-LCAFJ94Kg0pqNBajumEEsu/view?usp=sharing). Each class consists of 600 images for training and 50 images for validation. The training size is 90000 images and validation-7500 images. The total size of the dataset is 97500 128x128 RGB images. These images are not as small as CIFAR10 images and we can analyze modelsâ€™ interpretability much deeper and also achieve high performance. This subset which we call SmallImageNet150 is generated by randomly picking classes and images.

## Checkpoints

### CIFAR10

The architecture of the model which is used is ResNet18. The preturbations are generated with PGD L2 projection and epsilon 0.5.
| **Model** | **Standard Accuracy** | **Adversarial Accuracy** | **Checkpoint** |
|-----------|----------------------|--------------------------|--------------------------------------------------------------------------------------------|
| Standard | **92.7** | 0.72 | [here](https://drive.google.com/file/d/1t71KG_u-X-LCAFJ94Kg0pqNBajumEEsu/view?usp=sharing) |
| Robust | 85 | **64.6** | [here](https://drive.google.com/file/d/1t71KG_u-X-LCAFJ94Kg0pqNBajumEEsu/view?usp=sharing) |

### SmallImageNet150

The architecture of the model which is used is ResNet50. The preturbations are generated with PGD L2 projection and epsilon 0.5.

| **Model** | **Standard Accuracy** | **Adversarial Accuracy** | **Checkpoint**                                                                             |
| --------- | -------------------- | ------------------------ | ------------------------------------------------------------------------------------------ |
| Standard   | **75.9**             | 2.39                     | [here](https://drive.google.com/file/d/1zpHIJ_dPYb6-Seqtbk9YoWSItvdwU-GO/view?usp=sharing) |
| Robust    | 65.5                 | **53.2**                 | [here](https://drive.google.com/file/d/1_5bKIy4n0rtbRy0YK64BUblnBqUnISMv/view?usp=sharing) |

## Examples

| **Dataset**      | **Training**                                 | **Interpretability**                                    |
| ---------------- | -------------------------------------------- | ------------------------------------------------------- |
| CIFAR10          | [here](./examples/cifar10_train.ipynb)       | [here](./examples/cifar10_interpretability.ipynb)       |
| SmallImageNet150 | [here](./examples/smallimagenet_train.ipynb) | [here](./examples/smallimagenet_interpretability.ipynb) |
