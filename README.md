# Pytorch Trainers and Interpretability Evaluators

_(Increasing Computer Vision Models Interpretability)_

Contact: delyan.boychev05@gmail.com 

With the perpetual increase of complexity of the state-of-the-art deep neural networks, it becomes more
and more challenging to maintain their transparency. The scope of this work is to evaluate the effects
of the method called adversarial training which has been shown to make computer vision models more
explainable, but also make them robust, both important features of the models when we deploy them to
the real world. We study the impacts of adversarial training on the interpretability of the model using
techniques like Integrated Gradients, SHAP, Feature Visualization, Representations Inversion and one
new method called Class Specific Image Generation and compare models’ respective performances.

## SmallImageNet150

SmallImageNet150 dataset can be found [here](https://drive.google.com/file/d/1619V_hLgH3mhZSVCYuYO1G7y0088A1vq/view?usp=sharing) and its labels [here](https://drive.google.com/file/d/1t71KG_u-X-LCAFJ94Kg0pqNBajumEEsu/view?usp=sharing). Each class consists of 600 images for training and 50 images for validation. The training size is 90000 images and validation-7500 images. The total size of the dataset is 97500 128x128 RGB images. These images are not as small as CIFAR10 images and we can analyze models’ interpretability much deeper and also achieve high performance. This subset which we call SmallImageNet150 is generated by randomly picking classes and images.

## Checkpoints

### CIFAR10

The architecture of the model which is used is ResNet18. The models are evalutated on $l_2$ (constraint $\varepsilon = 0.5$ and step size $\sigma = 0.1$) and $l_{\infty}$  (constraint $\varepsilon = 4/255$ and step size $\sigma = 0.01$) adversaries generated with PGD.
| **Model**                         | **Standard Accuracy** | **$l_{2}$ Accuracy** | **$l_{\infty}$ Accuracy** | **Checkpoint**                                                                                |
|-----------------------------------|-----------------------|----------------------|---------------------------|-----------------------------------------------------------------------------------------------|
| Standard model                    | **93.2**              | 0.36                 | 0.13                      | [here](https://drive.google.com/file/d/1--6YSHDUNcwXvnjUgjdOcV_A3bMcHEbD/view?usp=sharing)    |
| Robust $l_{2}$ trained model      | 85                    | **64.6**             | 59.2                      | [here](https://drive.google.com/file/d/1OcvlvVlsC1oMIzZedvf3Zh6Q10kKzoyN/view?usp=sharing)    |
| Robust $l_{\infty}$ trained model | 80.4                  | 60.4                 | **65.1**                  | [here](https://drive.google.com/file/d/1_tI8peJe2hD037CgEzCh2k_wiFpH8tPe/view?usp=share_link) |
### SmallImageNet150

The architecture of the model which is used is ResNet50. The models are evalutated on $l_2$ (constraint $\varepsilon = 0.5$ and step size $\sigma = 0.1$) and $l_{\infty}$  (constraint $\varepsilon = 4/255$ and step size $\sigma = 0.1$) adversaries generated with PGD.

| **Model**                         | **Standard Accuracy** | **$l_{2}$ Accuracy** | **$l_{\infty}$ Accuracy** | **Checkpoint**                                                                             |
|-----------------------------------|-----------------------|----------------------|---------------------------|--------------------------------------------------------------------------------------------|
| Standard model                    | **75.9**              | 2.09                 | 0                         | [here](https://drive.google.com/file/d/1zpHIJ_dPYb6-Seqtbk9YoWSItvdwU-GO/view?usp=sharing) |
| Robust $l_{2}$ trained model      | 65.4                  | **53.2**             | 12.7                      | [here](https://drive.google.com/file/d/1_5bKIy4n0rtbRy0YK64BUblnBqUnISMv/view?usp=sharing) |
| Robust $l_{\infty}$ trained model | 60                    | 43.9                 | **32**                    | [here](https://drive.google.com/file/d/12O5HxjqcSzjt9-mGfapYeZ-nOfsMopIM/view?usp=sharing) |
## Examples

| **Dataset**      | **Training**                                 | **Interpretability**                                    |
| ---------------- | -------------------------------------------- | ------------------------------------------------------- |
| CIFAR10          | [here](./examples/cifar10_train.ipynb)       | [here](./examples/cifar10_interpretability.ipynb)       |
| SmallImageNet150 | [here](./examples/smallimagenet_train.ipynb) | [here](./examples/smallimagenet_interpretability.ipynb) |
